- actor_rollout_ref.model.path=/home/jinming/llm_models/Qwen2.5-7B
- data.tokenizer=/home/jinming/llm_models/Qwen2.5-7B
- data.train_files=[/home/jinming/Reasoning360-MTL/data/train/guru_18k/math.parquet]
- data.val_files=[/home/jinming/Reasoning360-MTL/data/validation/guru_3k/math.parquet]
- data.max_prompt_length=512
- data.max_response_length=1024
- data.train_batch_size=1
- data.gen_batch_size=1
- actor_rollout_ref.actor.ppo_mini_batch_size=1
- actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1
- critic.ppo_micro_batch_size_per_gpu=1
- actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=1
- actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=1
- actor_rollout_ref.rollout.gpu_memory_utilization=0.2
- ++actor_rollout_ref.rollout.max_model_len=1536
- actor_rollout_ref.rollout.n=1
- actor_rollout_ref.model.use_remove_padding=false
- trainer.nnodes=1
- trainer.n_gpus_per_node=4
- trainer.total_epochs=30
- trainer.val_before_train=false
- trainer.test_freq=0
- trainer.logger=[console]
- trainer.project_name=Reasoning360-MTL
- trainer.experiment_name=3274502-qwen2-7b-qwen2-7b-mtl
- ++trainer.ray_wait_register_center_timeout=300
- ++actor_rollout_ref.model.enable_flash_attention=false
- ++critic.model.enable_flash_attention=false
- ++actor_rollout_ref.model.enable_gradient_checkpointing=true
- ++critic.model.enable_gradient_checkpointing=true
- ++actor_rollout_ref.actor.fsdp_config.activation_offload=true
- ++critic.fsdp_config.param_offload=true
- ++critic.fsdp_config.optimizer_offload=true
- ++actor_rollout_ref.rollout.multi_turn.enable=false
- ++actor_rollout_ref.rollout.mode=sync
- mtl.enabled=false
- mtl.method=pcgrad
