/home/jinming/Reasoning360-MTL/verl/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
2025-08-05 10:40:55,450	INFO worker.py:1747 -- Connecting to existing Ray cluster at address: 10.128.9.117:6379...
2025-08-05 10:40:55,461	INFO worker.py:1927 -- Connected to Ray cluster.
[36m(pid=2651282)[0m /home/jinming/Reasoning360-MTL/verl/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=2651282)[0m   import pkg_resources
[36m(TaskRunner pid=2651282)[0m DeprecationWarning: `ray.state.available_resources_per_node` is a private attribute and access will be removed in a future Ray version.
[36m(TaskRunner pid=2651282)[0m WARNING:2025-08-05 10:41:17,361:Waiting for register center actor RpKUCL_register_center to be ready. Elapsed time: 0 seconds out of 300 seconds.
[36m(pid=2653631)[0m /home/jinming/Reasoning360-MTL/verl/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=2653631)[0m   import pkg_resources
[36m(pid=2653836)[0m /home/jinming/Reasoning360-MTL/verl/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=2653836)[0m   import pkg_resources
[36m(pid=2653837)[0m /home/jinming/Reasoning360-MTL/verl/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(pid=2653837)[0m   import pkg_resources
[36m(WorkerDict pid=2653631)[0m Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.
[36m(WorkerDict pid=2653631)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
[36m(pid=2653842)[0m /home/jinming/Reasoning360-MTL/verl/__init__.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.[32m [repeated 5x across cluster][0m
[36m(pid=2653842)[0m   import pkg_resources[32m [repeated 5x across cluster][0m
[36m(WorkerDict pid=2653836)[0m Loading checkpoint shards:  25%|â–ˆâ–ˆâ–Œ       | 1/4 [00:01<00:05,  1.99s/it]
[36m(WorkerDict pid=2653842)[0m Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.[32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2653842)[0m Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s][32m [repeated 7x across cluster][0m
[36m(WorkerDict pid=2653842)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:07<00:02,  2.37s/it][32m [repeated 17x across cluster][0m
[36m(WorkerDict pid=2653836)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.19s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:08<00:00,  2.16s/it]
[36m(TaskRunner pid=2651282)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_init_model()[39m (pid=2653842, ip=10.128.9.117, actor_id=9d45f3eab6195206309573ed01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x154ede35e7c0>)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/ray/base.py", line 733, in func
[36m(TaskRunner pid=2651282)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/base/decorator.py", line 680, in inner
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 553, in init_model
[36m(TaskRunner pid=2651282)[0m     self.rollout, self.rollout_sharding_manager = self._build_rollout(trust_remote_code=self.config.model.get("trust_remote_code", False))
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 425, in _build_rollout
[36m(TaskRunner pid=2651282)[0m     rollout = vllm_rollout_cls(model_path=local_path, config=self.config.rollout, tokenizer=self.tokenizer, model_hf_config=self.actor_model_config, device_mesh=rollout_device_mesh, trust_remote_code=trust_remote_code, **lora_kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 149, in __init__
[36m(TaskRunner pid=2651282)[0m     self.inference_engine = LLM(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 1161, in inner
[36m(TaskRunner pid=2651282)[0m     return fn(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/entrypoints/llm.py", line 247, in __init__
[36m(TaskRunner pid=2651282)[0m     self.llm_engine = LLMEngine.from_engine_args(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 510, in from_engine_args
[36m(TaskRunner pid=2651282)[0m     return engine_cls.from_vllm_config(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 486, in from_vllm_config
[36m(TaskRunner pid=2651282)[0m     return cls(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 278, in __init__
[36m(TaskRunner pid=2651282)[0m     self._initialize_kv_caches()
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 435, in _initialize_kv_caches
[36m(TaskRunner pid=2651282)[0m     self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/executor_base.py", line 123, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     self.collective_rpc("initialize_cache",
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
[36m(TaskRunner pid=2651282)[0m     answer = run_method(self.driver_worker, method, args, kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 2456, in run_method
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 311, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     raise_if_cache_size_invalid(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 560, in raise_if_cache_size_invalid
[36m(TaskRunner pid=2651282)[0m     raise ValueError("No available memory for the cache blocks. "
[36m(TaskRunner pid=2651282)[0m ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.
[36m(WorkerDict pid=2653841)[0m Loading checkpoint shards:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 3/4 [00:07<00:02,  2.48s/it][32m [repeated 6x across cluster][0m
[36m(WorkerDict pid=2653840)[0m Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.33s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:09<00:00,  2.40s/it][32m [repeated 7x across cluster][0m
Error executing job with overrides: ['data.train_files=[/home/jinming/Reasoning360-MTL/data/train/guru_18k/math.parquet]', 'data.val_files=[/home/jinming/Reasoning360-MTL/data/validation/guru_3k/math.parquet]', 'data.tokenizer=/home/jinming/llm_models/Qwen2.5-7B', 'data.max_prompt_length=256', 'data.max_response_length=512', 'data.train_batch_size=8', 'data.gen_batch_size=8', 'actor_rollout_ref.model.path=/home/jinming/llm_models/Qwen2.5-7B', 'actor_rollout_ref.actor.ppo_mini_batch_size=8', 'actor_rollout_ref.actor.ppo_micro_batch_size_per_gpu=1', 'actor_rollout_ref.ref.log_prob_micro_batch_size_per_gpu=1', 'actor_rollout_ref.rollout.log_prob_micro_batch_size_per_gpu=1', 'actor_rollout_ref.rollout.n=1', 'actor_rollout_ref.rollout.name=vllm', 'actor_rollout_ref.rollout.gpu_memory_utilization=0.05', '++actor_rollout_ref.rollout.max_model_len=128', '++actor_rollout_ref.rollout.max_num_seqs=1', '++actor_rollout_ref.rollout.enforce_eager=true', '++actor_rollout_ref.rollout.tensor_parallel_size=2', '++actor_rollout_ref.rollout.device_map=[6,7]', 'actor_rollout_ref.rollout.temperature=1.0', 'actor_rollout_ref.rollout.top_p=1.0', 'actor_rollout_ref.rollout.top_k=-1', 'trainer.nnodes=1', 'trainer.n_gpus_per_node=8', 'trainer.total_epochs=30', 'trainer.val_before_train=false', 'trainer.test_freq=0', 'trainer.save_freq=5', 'trainer.project_name=Reasoning360-MTL', 'trainer.logger=[console]', 'algorithm.adv_estimator=grpo', '++actor_rollout_ref.fsdp_config.param_offload=true', '++actor_rollout_ref.fsdp_config.optimizer_offload=true', '++actor_rollout_ref.fsdp_config.activation_offload=true', '++actor_rollout_ref.model.enable_flash_attention=false', '++actor_rollout_ref.model.enable_gradient_checkpointing=true', '++actor_rollout_ref.model.enable_activation_offload=true', '++actor_rollout_ref.actor.entropy_checkpointing=true', '++actor_rollout_ref.ref.entropy_from_logits_with_chunking=true', '++actor_rollout_ref.rollout.multi_turn.enable=false', '++actor_rollout_ref.rollout.mode=sync', '+trainer.early_stopping_min_epochs=10', '+trainer.early_stopping_patience=5']
Traceback (most recent call last):
  File "/home/jinming/Reasoning360-MTL/verl/trainer/main_ppo.py", line 27, in main
    run_ppo(config)
  File "/home/jinming/Reasoning360-MTL/verl/trainer/main_ppo.py", line 39, in run_ppo
    ray.get(runner.run.remote(config))
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/ray/_private/auto_init_hook.py", line 22, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/ray/_private/client_mode_hook.py", line 104, in wrapper
    return func(*args, **kwargs)
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/ray/_private/worker.py", line 2858, in get
    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/ray/_private/worker.py", line 958, in get_objects
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(ValueError): [36mray::TaskRunner.run()[39m (pid=2651282, ip=10.128.9.117, actor_id=e2a1f8c86ad9d6b7207798d501000000, repr=<main_ppo.TaskRunner object at 0x154eefe03d60>)
  File "/home/jinming/Reasoning360-MTL/verl/trainer/main_ppo.py", line 154, in run
    trainer.init_workers()
  File "/home/jinming/Reasoning360-MTL/verl/trainer/ppo/ray_trainer.py", line 736, in init_workers
    self.actor_rollout_wg.init_model()
  File "/home/jinming/Reasoning360-MTL/verl/single_controller/ray/base.py", line 51, in __call__
    output = ray.get(output)
ray.exceptions.RayTaskError(ValueError): [36mray::WorkerDict.actor_rollout_init_model()[39m (pid=2653840, ip=10.128.9.117, actor_id=41a8609a7b0bd10133483cd001000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x154ede35f1f0>)
  File "/home/jinming/Reasoning360-MTL/verl/single_controller/ray/base.py", line 733, in func
    return getattr(self.worker_dict[key], name)(*args, **kwargs)
  File "/home/jinming/Reasoning360-MTL/verl/single_controller/base/decorator.py", line 680, in inner
    return func(*args, **kwargs)
  File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 553, in init_model
    self.rollout, self.rollout_sharding_manager = self._build_rollout(trust_remote_code=self.config.model.get("trust_remote_code", False))
  File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 425, in _build_rollout
    rollout = vllm_rollout_cls(model_path=local_path, config=self.config.rollout, tokenizer=self.tokenizer, model_hf_config=self.actor_model_config, device_mesh=rollout_device_mesh, trust_remote_code=trust_remote_code, **lora_kwargs)
  File "/home/jinming/Reasoning360-MTL/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 149, in __init__
    self.inference_engine = LLM(
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 1161, in inner
    return fn(*args, **kwargs)
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/entrypoints/llm.py", line 247, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 510, in from_engine_args
    return engine_cls.from_vllm_config(
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 486, in from_vllm_config
    return cls(
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 278, in __init__
    self._initialize_kv_caches()
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 435, in _initialize_kv_caches
    self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/executor_base.py", line 123, in initialize_cache
    self.collective_rpc("initialize_cache",
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
    answer = run_method(self.driver_worker, method, args, kwargs)
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 2456, in run_method
    return func(*args, **kwargs)
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 311, in initialize_cache
    raise_if_cache_size_invalid(
  File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 560, in raise_if_cache_size_invalid
    raise ValueError("No available memory for the cache blocks. "
ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
[36m(TaskRunner pid=2651282)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_init_model()[39m (pid=2653841, ip=10.128.9.117, actor_id=40d8e51732630fb0e421285f01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x154ede35f1f0>)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/ray/base.py", line 733, in func
[36m(TaskRunner pid=2651282)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/base/decorator.py", line 680, in inner
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 553, in init_model
[36m(TaskRunner pid=2651282)[0m     self.rollout, self.rollout_sharding_manager = self._build_rollout(trust_remote_code=self.config.model.get("trust_remote_code", False))
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 425, in _build_rollout
[36m(TaskRunner pid=2651282)[0m     rollout = vllm_rollout_cls(model_path=local_path, config=self.config.rollout, tokenizer=self.tokenizer, model_hf_config=self.actor_model_config, device_mesh=rollout_device_mesh, trust_remote_code=trust_remote_code, **lora_kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 149, in __init__
[36m(TaskRunner pid=2651282)[0m     self.inference_engine = LLM(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 1161, in inner
[36m(TaskRunner pid=2651282)[0m     return fn(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/entrypoints/llm.py", line 247, in __init__
[36m(TaskRunner pid=2651282)[0m     self.llm_engine = LLMEngine.from_engine_args(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 510, in from_engine_args
[36m(TaskRunner pid=2651282)[0m     return engine_cls.from_vllm_config(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 486, in from_vllm_config
[36m(TaskRunner pid=2651282)[0m     return cls(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 278, in __init__
[36m(TaskRunner pid=2651282)[0m     self._initialize_kv_caches()
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 435, in _initialize_kv_caches
[36m(TaskRunner pid=2651282)[0m     self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/executor_base.py", line 123, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     self.collective_rpc("initialize_cache",
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
[36m(TaskRunner pid=2651282)[0m     answer = run_method(self.driver_worker, method, args, kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 2456, in run_method
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 311, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     raise_if_cache_size_invalid(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 560, in raise_if_cache_size_invalid
[36m(TaskRunner pid=2651282)[0m     raise ValueError("No available memory for the cache blocks. "
[36m(TaskRunner pid=2651282)[0m ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.
[36m(TaskRunner pid=2651282)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_init_model()[39m (pid=2653839, ip=10.128.9.117, actor_id=2bcd62ea9139d59fd817c82701000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x154ede35e880>)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/ray/base.py", line 733, in func
[36m(TaskRunner pid=2651282)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/base/decorator.py", line 680, in inner
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 553, in init_model
[36m(TaskRunner pid=2651282)[0m     self.rollout, self.rollout_sharding_manager = self._build_rollout(trust_remote_code=self.config.model.get("trust_remote_code", False))
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 425, in _build_rollout
[36m(TaskRunner pid=2651282)[0m     rollout = vllm_rollout_cls(model_path=local_path, config=self.config.rollout, tokenizer=self.tokenizer, model_hf_config=self.actor_model_config, device_mesh=rollout_device_mesh, trust_remote_code=trust_remote_code, **lora_kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 149, in __init__
[36m(TaskRunner pid=2651282)[0m     self.inference_engine = LLM(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 1161, in inner
[36m(TaskRunner pid=2651282)[0m     return fn(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/entrypoints/llm.py", line 247, in __init__
[36m(TaskRunner pid=2651282)[0m     self.llm_engine = LLMEngine.from_engine_args(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 510, in from_engine_args
[36m(TaskRunner pid=2651282)[0m     return engine_cls.from_vllm_config(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 486, in from_vllm_config
[36m(TaskRunner pid=2651282)[0m     return cls(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 278, in __init__
[36m(TaskRunner pid=2651282)[0m     self._initialize_kv_caches()
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 435, in _initialize_kv_caches
[36m(TaskRunner pid=2651282)[0m     self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/executor_base.py", line 123, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     self.collective_rpc("initialize_cache",
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
[36m(TaskRunner pid=2651282)[0m     answer = run_method(self.driver_worker, method, args, kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 2456, in run_method
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 311, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     raise_if_cache_size_invalid(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 560, in raise_if_cache_size_invalid
[36m(TaskRunner pid=2651282)[0m     raise ValueError("No available memory for the cache blocks. "
[36m(TaskRunner pid=2651282)[0m ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.
[36m(TaskRunner pid=2651282)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_init_model()[39m (pid=2653838, ip=10.128.9.117, actor_id=cbab1230384621306451965c01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x154ede35e3d0>)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/ray/base.py", line 733, in func
[36m(TaskRunner pid=2651282)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/base/decorator.py", line 680, in inner
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 553, in init_model
[36m(TaskRunner pid=2651282)[0m     self.rollout, self.rollout_sharding_manager = self._build_rollout(trust_remote_code=self.config.model.get("trust_remote_code", False))
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 425, in _build_rollout
[36m(TaskRunner pid=2651282)[0m     rollout = vllm_rollout_cls(model_path=local_path, config=self.config.rollout, tokenizer=self.tokenizer, model_hf_config=self.actor_model_config, device_mesh=rollout_device_mesh, trust_remote_code=trust_remote_code, **lora_kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 149, in __init__
[36m(TaskRunner pid=2651282)[0m     self.inference_engine = LLM(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 1161, in inner
[36m(TaskRunner pid=2651282)[0m     return fn(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/entrypoints/llm.py", line 247, in __init__
[36m(TaskRunner pid=2651282)[0m     self.llm_engine = LLMEngine.from_engine_args(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 510, in from_engine_args
[36m(TaskRunner pid=2651282)[0m     return engine_cls.from_vllm_config(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 486, in from_vllm_config
[36m(TaskRunner pid=2651282)[0m     return cls(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 278, in __init__
[36m(TaskRunner pid=2651282)[0m     self._initialize_kv_caches()
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 435, in _initialize_kv_caches
[36m(TaskRunner pid=2651282)[0m     self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/executor_base.py", line 123, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     self.collective_rpc("initialize_cache",
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
[36m(TaskRunner pid=2651282)[0m     answer = run_method(self.driver_worker, method, args, kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 2456, in run_method
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 311, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     raise_if_cache_size_invalid(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 560, in raise_if_cache_size_invalid
[36m(TaskRunner pid=2651282)[0m     raise ValueError("No available memory for the cache blocks. "
[36m(TaskRunner pid=2651282)[0m ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.
[36m(TaskRunner pid=2651282)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_init_model()[39m (pid=2653837, ip=10.128.9.117, actor_id=2f5806e9341d1610a98a508701000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x154ede35f940>)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/ray/base.py", line 733, in func
[36m(TaskRunner pid=2651282)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/base/decorator.py", line 680, in inner
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 553, in init_model
[36m(TaskRunner pid=2651282)[0m     self.rollout, self.rollout_sharding_manager = self._build_rollout(trust_remote_code=self.config.model.get("trust_remote_code", False))
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 425, in _build_rollout
[36m(TaskRunner pid=2651282)[0m     rollout = vllm_rollout_cls(model_path=local_path, config=self.config.rollout, tokenizer=self.tokenizer, model_hf_config=self.actor_model_config, device_mesh=rollout_device_mesh, trust_remote_code=trust_remote_code, **lora_kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 149, in __init__
[36m(TaskRunner pid=2651282)[0m     self.inference_engine = LLM(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 1161, in inner
[36m(TaskRunner pid=2651282)[0m     return fn(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/entrypoints/llm.py", line 247, in __init__
[36m(TaskRunner pid=2651282)[0m     self.llm_engine = LLMEngine.from_engine_args(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 510, in from_engine_args
[36m(TaskRunner pid=2651282)[0m     return engine_cls.from_vllm_config(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 486, in from_vllm_config
[36m(TaskRunner pid=2651282)[0m     return cls(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 278, in __init__
[36m(TaskRunner pid=2651282)[0m     self._initialize_kv_caches()
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 435, in _initialize_kv_caches
[36m(TaskRunner pid=2651282)[0m     self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/executor_base.py", line 123, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     self.collective_rpc("initialize_cache",
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
[36m(TaskRunner pid=2651282)[0m     answer = run_method(self.driver_worker, method, args, kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 2456, in run_method
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 311, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     raise_if_cache_size_invalid(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 560, in raise_if_cache_size_invalid
[36m(TaskRunner pid=2651282)[0m     raise ValueError("No available memory for the cache blocks. "
[36m(TaskRunner pid=2651282)[0m ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.
[36m(TaskRunner pid=2651282)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_init_model()[39m (pid=2653836, ip=10.128.9.117, actor_id=14dbee6e71bb58f99064e3cd01000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x154ede367880>)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/ray/base.py", line 733, in func
[36m(TaskRunner pid=2651282)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/base/decorator.py", line 680, in inner
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 553, in init_model
[36m(TaskRunner pid=2651282)[0m     self.rollout, self.rollout_sharding_manager = self._build_rollout(trust_remote_code=self.config.model.get("trust_remote_code", False))
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 425, in _build_rollout
[36m(TaskRunner pid=2651282)[0m     rollout = vllm_rollout_cls(model_path=local_path, config=self.config.rollout, tokenizer=self.tokenizer, model_hf_config=self.actor_model_config, device_mesh=rollout_device_mesh, trust_remote_code=trust_remote_code, **lora_kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 149, in __init__
[36m(TaskRunner pid=2651282)[0m     self.inference_engine = LLM(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 1161, in inner
[36m(TaskRunner pid=2651282)[0m     return fn(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/entrypoints/llm.py", line 247, in __init__
[36m(TaskRunner pid=2651282)[0m     self.llm_engine = LLMEngine.from_engine_args(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 510, in from_engine_args
[36m(TaskRunner pid=2651282)[0m     return engine_cls.from_vllm_config(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 486, in from_vllm_config
[36m(TaskRunner pid=2651282)[0m     return cls(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 278, in __init__
[36m(TaskRunner pid=2651282)[0m     self._initialize_kv_caches()
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 435, in _initialize_kv_caches
[36m(TaskRunner pid=2651282)[0m     self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/executor_base.py", line 123, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     self.collective_rpc("initialize_cache",
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
[36m(TaskRunner pid=2651282)[0m     answer = run_method(self.driver_worker, method, args, kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 2456, in run_method
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 311, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     raise_if_cache_size_invalid(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 560, in raise_if_cache_size_invalid
[36m(TaskRunner pid=2651282)[0m     raise ValueError("No available memory for the cache blocks. "
[36m(TaskRunner pid=2651282)[0m ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.
[36m(TaskRunner pid=2651282)[0m Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::WorkerDict.actor_rollout_init_model()[39m (pid=2653631, ip=10.128.9.117, actor_id=76d8c7e3f405ceaa148e155001000000, repr=<verl.single_controller.ray.base.WorkerDict object at 0x154ede35ef70>)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/ray/base.py", line 733, in func
[36m(TaskRunner pid=2651282)[0m     return getattr(self.worker_dict[key], name)(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/single_controller/base/decorator.py", line 680, in inner
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 553, in init_model
[36m(TaskRunner pid=2651282)[0m     self.rollout, self.rollout_sharding_manager = self._build_rollout(trust_remote_code=self.config.model.get("trust_remote_code", False))
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/fsdp_workers.py", line 425, in _build_rollout
[36m(TaskRunner pid=2651282)[0m     rollout = vllm_rollout_cls(model_path=local_path, config=self.config.rollout, tokenizer=self.tokenizer, model_hf_config=self.actor_model_config, device_mesh=rollout_device_mesh, trust_remote_code=trust_remote_code, **lora_kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/Reasoning360-MTL/verl/workers/rollout/vllm_rollout/vllm_rollout_spmd.py", line 149, in __init__
[36m(TaskRunner pid=2651282)[0m     self.inference_engine = LLM(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 1161, in inner
[36m(TaskRunner pid=2651282)[0m     return fn(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/entrypoints/llm.py", line 247, in __init__
[36m(TaskRunner pid=2651282)[0m     self.llm_engine = LLMEngine.from_engine_args(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 510, in from_engine_args
[36m(TaskRunner pid=2651282)[0m     return engine_cls.from_vllm_config(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 486, in from_vllm_config
[36m(TaskRunner pid=2651282)[0m     return cls(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 278, in __init__
[36m(TaskRunner pid=2651282)[0m     self._initialize_kv_caches()
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/engine/llm_engine.py", line 435, in _initialize_kv_caches
[36m(TaskRunner pid=2651282)[0m     self.model_executor.initialize_cache(num_gpu_blocks, num_cpu_blocks)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/executor_base.py", line 123, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     self.collective_rpc("initialize_cache",
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/executor/uniproc_executor.py", line 56, in collective_rpc
[36m(TaskRunner pid=2651282)[0m     answer = run_method(self.driver_worker, method, args, kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/utils.py", line 2456, in run_method
[36m(TaskRunner pid=2651282)[0m     return func(*args, **kwargs)
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 311, in initialize_cache
[36m(TaskRunner pid=2651282)[0m     raise_if_cache_size_invalid(
[36m(TaskRunner pid=2651282)[0m   File "/home/jinming/venv_reasoning360mtl/lib64/python3.9/site-packages/vllm/worker/worker.py", line 560, in raise_if_cache_size_invalid
[36m(TaskRunner pid=2651282)[0m     raise ValueError("No available memory for the cache blocks. "
[36m(TaskRunner pid=2651282)[0m ValueError: No available memory for the cache blocks. Try increasing `gpu_memory_utilization` when initializing the engine.
